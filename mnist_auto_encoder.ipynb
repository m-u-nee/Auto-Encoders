{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" The following code is a simple implementation of a variational autoencoder, or VAE, in PyTorch.\n",
    "The autoencoder is trained on the MNIST dataset. \n",
    "The code follows the following structure:\n",
    "1. Import libraries, load and preprocess the data\n",
    "2. Define the AE architecture\n",
    "3. Create an instance of the AE and train it\n",
    "4. Generate samples from the trained AE\n",
    "5. Visualize the results of compression and generation\n",
    "6. Analyze the latent space of the AE\n",
    "7. Create a k-NN classifier on the latent space\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "device = torch.device('mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mnist \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize and Reshape images (flatten)\n",
    "x_train, x_test = torch.tensor(x_train.astype('float32')/255.), torch.tensor(x_test.astype('float32')/255.).to(device)\n",
    "x_train_flat, x_test_flat = x_train.reshape(x_train.shape[0], -1), x_test.reshape(x_test.shape[0], -1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "batch_size = 64 \n",
    "\n",
    "train_dataset = TensorDataset(x_train_flat)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, use_hidden_layer=False, hidden_dim=32, BCE = False):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.BCE = BCE\n",
    "        self.latent_dim = latent_dim \n",
    "        # Encoder\n",
    "        if use_hidden_layer:\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, latent_dim),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        else:\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Linear(input_dim, latent_dim),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        # Decoder\n",
    "        if use_hidden_layer:\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Linear(latent_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, input_dim),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        else:\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Linear(latent_dim, input_dim),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self, x, y=None, output_latent=False):\n",
    "        latent = self.encoder(x)\n",
    "        output = self.decoder(latent)\n",
    "        if output_latent:\n",
    "            return latent\n",
    "        if y is None:\n",
    "            return output\n",
    "        else:\n",
    "            if self.BCE == True:\n",
    "                loss = F.binary_cross_entropy(output, y, reduction='sum')\n",
    "            else:\n",
    "                loss = F.mse_loss(output, y)\n",
    "            return output, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(input_dim=784, latent_dim=32, use_hidden_layer=True, hidden_dim=512, BCE = True).to(device)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "lossi = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 50\n",
    "for e in range(epochs):\n",
    "    for batch in train_loader: \n",
    "        x_batch = batch[0].to(device)\n",
    "\n",
    "        output, loss = model(x=x_batch, y=x_batch)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        lossi.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if e % 1 == 0:\n",
    "        print(f'{e}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossi)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Losses over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# print average over last 1000 losses\n",
    "print(np.mean(lossi[-1000:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rand = random.randint(0,9999)\n",
    "output = model.forward(x_test_flat[rand])\n",
    "print(y_test[rand])\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(x_test_flat[rand].cpu().reshape(28,28), cmap='gray')\n",
    "\n",
    "# Display the generated image\n",
    "output_scaled = output\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Generated Image\")\n",
    "plt.imshow(output.reshape(28,28).detach().cpu(), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming model, x_test_flat, and y_test are already defined and loaded\n",
    "\n",
    "# # Calculate losses for all test images\n",
    "# losses = []\n",
    "# outputs = []\n",
    "# for i in range(10000):\n",
    "#     output, loss = model(x=x_test_flat[i], y=x_test_flat[i])\n",
    "#     losses.append(loss.item())\n",
    "#     outputs.append(output)\n",
    "\n",
    "# # Convert lists to tensors for easier indexing\n",
    "# losses = torch.tensor(losses)\n",
    "# outputs = torch.stack(outputs)\n",
    "\n",
    "# # Find indices of the 10 lowest and 10 highest losses\n",
    "# lowest_losses_indices = torch.argsort(losses)[:10]\n",
    "# highest_losses_indices = torch.argsort(losses, descending=True)[:10]\n",
    "\n",
    "# # Display the original and generated images with lowest losses\n",
    "# plt.figure(figsize=(20, 8))\n",
    "# for idx, i in enumerate(lowest_losses_indices):\n",
    "#     plt.subplot(2, 10, idx + 1)\n",
    "#     plt.title(f\"Orig {idx+1}\")\n",
    "#     plt.imshow(x_test_flat[i].cpu().reshape(28, 28), cmap='gray')\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.subplot(2, 10, idx + 11)\n",
    "#     plt.title(f\"Gen {idx+1}\")\n",
    "#     plt.imshow(outputs[i].reshape(28, 28).detach().cpu(), cmap='gray')\n",
    "#     plt.axis('off')\n",
    "\n",
    "# plt.suptitle(\"10 Best Reconstructions (Lowest Losses)\")\n",
    "# plt.show()\n",
    "\n",
    "# # Display the original and generated images with highest losses\n",
    "# plt.figure(figsize=(20, 8))\n",
    "# for idx, i in enumerate(highest_losses_indices):\n",
    "#     plt.subplot(2, 10, idx + 1)\n",
    "#     plt.title(f\"Orig {idx+1}\")\n",
    "#     plt.imshow(x_test_flat[i].cpu().reshape(28, 28), cmap='gray')\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     plt.subplot(2, 10, idx + 11)\n",
    "#     plt.title(f\"Gen {idx+1}\")\n",
    "#     plt.imshow(outputs[i].reshape(28, 28).detach().cpu(), cmap='gray')\n",
    "#     plt.axis('off')\n",
    "\n",
    "# plt.suptitle(\"10 Worst Reconstructions (Highest Losses)\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the case of a 2d latent space, we can visualize the latent space by plotting the color coded latent vectors of the test images\n",
    "if model.latent_dim == 2:\n",
    "    latent_vectors = model.forward(x_test_flat, output_latent=True).detach().cpu().numpy()\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(latent_vectors[:, 0], latent_vectors[:, 1], c=y_test, cmap='tab10')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"Latent X\")\n",
    "    plt.ylabel(\"Latent Y\")\n",
    "    plt.title(\"2D Latent Space Visualization\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a bar graph of the average loss for each digit\n",
    "# average_losses = []\n",
    "# for i in range(10):\n",
    "#     indices = (y_test == i)\n",
    "#     average_loss = torch.mean(losses[indices]).item()\n",
    "#     average_losses.append(average_loss)\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.bar(range(10), average_losses)\n",
    "# plt.xticks(range(10))\n",
    "# plt.xlabel(\"Digit\")\n",
    "# plt.ylabel(\"Average Loss\")\n",
    "# plt.title(\"Average Loss per Digit\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def plot_latent_space_distances(model, x_test_flat, y_test, num_instances=10, metric='dot_product'):\n",
    "    # Find specified number of instances of each digit\n",
    "    instances = []\n",
    "    for i in range(10):\n",
    "        indices = (y_test == i)\n",
    "        digit_instances = x_test_flat[indices][:num_instances]  # Get num_instances for each digit\n",
    "        instances.append(digit_instances)\n",
    "\n",
    "    # Concatenate all instances\n",
    "    instances = torch.cat(instances)\n",
    "    instances = instances.view(-1, x_test_flat.shape[1])  # Flatten the instances if not already\n",
    "\n",
    "    # Calculate latent space representation of each instance\n",
    "    latent_vectors = model.forward(instances, output_latent=True).detach().cpu().numpy()\n",
    "\n",
    "    # Reshape latent vectors to have a separate axis for each digit\n",
    "    latent_vectors = latent_vectors.reshape(10, num_instances, -1)\n",
    "\n",
    "    # Calculate the desired metric between each digit's latent space representation and all other digits\n",
    "    average_distances = np.zeros((10, 10))\n",
    "\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            if metric == 'dot_product':\n",
    "                distance = np.mean([np.dot(latent_vectors[i, k], latent_vectors[j, l]) for k in range(num_instances) for l in range(num_instances)])\n",
    "            elif metric == 'euclidean':\n",
    "                distance = np.mean([np.linalg.norm(latent_vectors[i, k] - latent_vectors[j, l]) for k in range(num_instances) for l in range(num_instances)])\n",
    "            elif metric == 'manhattan':\n",
    "                distance = np.mean([np.sum(np.abs(latent_vectors[i, k] - latent_vectors[j, l])) for k in range(num_instances) for l in range(num_instances)])\n",
    "            elif metric == 'cosine':\n",
    "                distance = np.mean([cosine_similarity(latent_vectors[i, k].reshape(1, -1), latent_vectors[j, l].reshape(1, -1))[0][0] for k in range(num_instances) for l in range(num_instances)])\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown metric: {metric}\")\n",
    "            average_distances[i, j] = distance\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(average_distances, cmap='viridis')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks(range(10))\n",
    "    plt.xlabel(\"Digit\")\n",
    "    plt.ylabel(\"Digit\")\n",
    "    plt.title(f\"Average {metric.replace('_', ' ').capitalize()} Between Digits in Latent Space ({num_instances} Instances Each)\")\n",
    "    plt.show()\n",
    "\n",
    "# Usage example:\n",
    "# Assuming model, x_test_flat, y_test are already defined and loaded.\n",
    "plot_latent_space_distances(model, x_test_flat, y_test, num_instances=100, metric='cosine')  # You can specify any metric: 'dot_product', 'euclidean', 'manhattan', 'cosine'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
